functionality:
  name: "msdial_gcms"
  namespace: "msdial"
  version: "main_build"
  authors:
  - name: "Robrecht Cannoodt"
    email: "rcannood@gmail.com"
    roles:
    - "maintainer"
    props:
      github: "rcannood"
      orcid: "0000-0003-3641-729X"
  inputs:
  - type: "file"
    name: "--input"
    alternatives: []
    description: "One or more ABF files. Can also be a directory of ABF files."
    example:
    - "input.abf"
    default: []
    must_exist: false
    required: true
    direction: "input"
    multiple: true
    multiple_sep: ":"
  outputs:
  - type: "file"
    name: "--output"
    alternatives: []
    description: "An output directory to store the 'mqpar.xml' and 'combined' outputs."
    example:
    - "output_dir"
    default: []
    must_exist: false
    required: true
    direction: "output"
    multiple: false
    multiple_sep: ":"
  arguments:
  - type: "string"
    name: "--data_type"
    alternatives: []
    example: []
    default:
    - "Centroid"
    required: false
    choices:
    - "Centroid"
    - "Profile"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--ion_mode"
    alternatives: []
    example: []
    default:
    - "Positive"
    required: false
    choices:
    - "Positive"
    - "Negative"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--accuracy_type"
    alternatives: []
    example: []
    default:
    - "IsNominal"
    required: false
    choices:
    - "IsNominal"
    - "IsAccurate"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--retention_time_begin"
    alternatives: []
    example: []
    default:
    - 0
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--retention_time_end"
    alternatives: []
    example: []
    default:
    - 25
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--mass_range_begin"
    alternatives: []
    example: []
    default:
    - 0
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--mass_range_end"
    alternatives: []
    example: []
    default:
    - 1000
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--smoothing_method"
    alternatives: []
    example: []
    default:
    - "LinearWeightedMovingAverage"
    required: false
    choices:
    - "SimpleMovingAverage"
    - "LinearWeightedMovingAverage"
    - "SavitzkyGolayFilter"
    - "BinomialFilter"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--smoothing_level"
    alternatives: []
    example: []
    default:
    - 3
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--average_peak_width"
    alternatives: []
    example: []
    default:
    - 20
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--minimum_peak_height"
    alternatives: []
    example: []
    default:
    - 1000
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--mass_slice_width"
    alternatives: []
    example: []
    default:
    - 0.1
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--mass_accuracy"
    alternatives: []
    example: []
    default:
    - 0.025
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--sigma_window_value"
    alternatives: []
    example: []
    default:
    - 0.5
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--amplitude_cutoff"
    alternatives: []
    example: []
    default:
    - 10
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--msp_file"
    alternatives: []
    example:
    - "file.msp"
    default: []
    must_exist: false
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "file"
    name: "--ri_index_file"
    alternatives: []
    example:
    - "ri_index.txt"
    default: []
    must_exist: false
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--retention_type"
    alternatives: []
    example: []
    default:
    - "RI"
    required: false
    choices:
    - "RI"
    - "RT"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--ri_compound"
    alternatives: []
    example: []
    default:
    - "Alkanes"
    required: false
    choices:
    - "Fames"
    - "Alkanes"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--retention_time_tolerance_for_identification"
    alternatives: []
    example: []
    default:
    - 0.5
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--retention_index_tolerance_for_identification"
    alternatives: []
    example: []
    default:
    - 20
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--ei_similarity_tolerance_for_identification"
    alternatives: []
    example: []
    default:
    - 70
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--identification_score_cutoff"
    alternatives: []
    example: []
    default:
    - 70
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "string"
    name: "--alignment_index_type"
    alternatives: []
    example: []
    default:
    - "RT"
    required: false
    choices:
    - "RI"
    - "RT"
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--retention_time_tolerance_for_alignment"
    alternatives: []
    example: []
    default:
    - 0.075
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--retention_index_tolerance_for_alignment"
    alternatives: []
    example: []
    default:
    - 20
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--ei_similarity_tolerance_for_alignment"
    alternatives: []
    example: []
    default:
    - 70
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--retention_time_factor_for_alignment"
    alternatives: []
    example: []
    default:
    - 0.5
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "double"
    name: "--ei_similarity_factor_for_alignment"
    alternatives: []
    example: []
    default:
    - 0.5
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "integer"
    name: "--peak_count_filter"
    alternatives: []
    example: []
    default:
    - 0
    required: false
    choices: []
    direction: "input"
    multiple: false
    multiple_sep: ":"
  - type: "boolean"
    name: "--qc_at_least_filter"
    alternatives: []
    example: []
    default:
    - true
    required: false
    direction: "input"
    multiple: false
    multiple_sep: ":"
  resources:
  - type: "file"
    text: |
      // msdial_gcms main_build
      // 
      // This wrapper script is auto-generated by viash 0.5.12 and is thus a derivative
      // work thereof. This software comes with ABSOLUTELY NO WARRANTY from Data
      // Intuitive.
      // 
      // The component may contain files which fall under a different license. The
      // authors of this component should specify the license in the header of such
      // files, or include a separate license file detailing the licenses of all included
      // files.
      // 
      // Component authors:
      //  * Robrecht Cannoodt <rcannood@gmail.com> (maintainer) {github: rcannood, orcid:
      // 0000-0003-3641-729X}
      
      nextflow.enable.dsl=2
      
      // Required imports
      import groovy.json.JsonSlurper
      
      // initialise slurper
      def jsonSlurper = new JsonSlurper()
      
      // DEFINE CUSTOM CODE
      
      // functionality metadata
      thisFunctionality = [
        'name': 'msdial_gcms',
        'arguments': [
          [
            'name': 'input',
            'required': true,
            'type': 'file',
            'direction': 'input',
            'description': 'One or more ABF files. Can also be a directory of ABF files.',
            'example': ['input.abf'],
            'multiple': true,
            'multiple_sep': ':'
          ],
          [
            'name': 'output',
            'required': true,
            'type': 'file',
            'direction': 'output',
            'description': 'An output directory to store the \'mqpar.xml\' and \'combined\' outputs.',
            'default': '$id.$key.output',
            'example': 'output_dir',
            'multiple': false
          ],
          [
            'name': 'data_type',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'Centroid',
            'multiple': false
          ],
          [
            'name': 'ion_mode',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'Positive',
            'multiple': false
          ],
          [
            'name': 'accuracy_type',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'IsNominal',
            'multiple': false
          ],
          [
            'name': 'retention_time_begin',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 0,
            'multiple': false
          ],
          [
            'name': 'retention_time_end',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 25,
            'multiple': false
          ],
          [
            'name': 'mass_range_begin',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 0,
            'multiple': false
          ],
          [
            'name': 'mass_range_end',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 1000,
            'multiple': false
          ],
          [
            'name': 'smoothing_method',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'LinearWeightedMovingAverage',
            'multiple': false
          ],
          [
            'name': 'smoothing_level',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 3,
            'multiple': false
          ],
          [
            'name': 'average_peak_width',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 20,
            'multiple': false
          ],
          [
            'name': 'minimum_peak_height',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 1000,
            'multiple': false
          ],
          [
            'name': 'mass_slice_width',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.1,
            'multiple': false
          ],
          [
            'name': 'mass_accuracy',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.025,
            'multiple': false
          ],
          [
            'name': 'sigma_window_value',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.5,
            'multiple': false
          ],
          [
            'name': 'amplitude_cutoff',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 10,
            'multiple': false
          ],
          [
            'name': 'msp_file',
            'required': false,
            'type': 'file',
            'direction': 'input',
            'example': 'file.msp',
            'multiple': false
          ],
          [
            'name': 'ri_index_file',
            'required': false,
            'type': 'file',
            'direction': 'input',
            'example': 'ri_index.txt',
            'multiple': false
          ],
          [
            'name': 'retention_type',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'RI',
            'multiple': false
          ],
          [
            'name': 'ri_compound',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'Alkanes',
            'multiple': false
          ],
          [
            'name': 'retention_time_tolerance_for_identification',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.5,
            'multiple': false
          ],
          [
            'name': 'retention_index_tolerance_for_identification',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 20,
            'multiple': false
          ],
          [
            'name': 'ei_similarity_tolerance_for_identification',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 70,
            'multiple': false
          ],
          [
            'name': 'identification_score_cutoff',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 70,
            'multiple': false
          ],
          [
            'name': 'alignment_index_type',
            'required': false,
            'type': 'string',
            'direction': 'input',
            'default': 'RT',
            'multiple': false
          ],
          [
            'name': 'retention_time_tolerance_for_alignment',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.075,
            'multiple': false
          ],
          [
            'name': 'retention_index_tolerance_for_alignment',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 20,
            'multiple': false
          ],
          [
            'name': 'ei_similarity_tolerance_for_alignment',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 70,
            'multiple': false
          ],
          [
            'name': 'retention_time_factor_for_alignment',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.5,
            'multiple': false
          ],
          [
            'name': 'ei_similarity_factor_for_alignment',
            'required': false,
            'type': 'double',
            'direction': 'input',
            'default': 0.5,
            'multiple': false
          ],
          [
            'name': 'peak_count_filter',
            'required': false,
            'type': 'integer',
            'direction': 'input',
            'default': 0,
            'multiple': false
          ],
          [
            'name': 'qc_at_least_filter',
            'required': false,
            'type': 'boolean',
            'direction': 'input',
            'default': true,
            'multiple': false
          ]
        ]
      ]
      
      thisHelpMessage = '''msdial_gcms main_build
      
      Options:
          --input
              type: file, required parameter, multiple values allowed
              example: input.abf
              One or more ABF files. Can also be a directory of ABF files.
      
          --output
              type: file, required parameter, output
              example: output_dir
              An output directory to store the 'mqpar.xml' and 'combined' outputs.
      
          --data_type
              type: string
              default: Centroid
              choices:
                  - Centroid
                  - Profile
      
          --ion_mode
              type: string
              default: Positive
              choices:
                  - Positive
                  - Negative
      
          --accuracy_type
              type: string
              default: IsNominal
              choices:
                  - IsNominal
                  - IsAccurate
      
          --retention_time_begin
              type: integer
              default: 0
      
          --retention_time_end
              type: integer
              default: 25
      
          --mass_range_begin
              type: integer
              default: 0
      
          --mass_range_end
              type: integer
              default: 1000
      
          --smoothing_method
              type: string
              default: LinearWeightedMovingAverage
              choices:
                  - SimpleMovingAverage
                  - LinearWeightedMovingAverage
                  - SavitzkyGolayFilter
                  - BinomialFilter
      
          --smoothing_level
              type: integer
              default: 3
      
          --average_peak_width
              type: integer
              default: 20
      
          --minimum_peak_height
              type: integer
              default: 1000
      
          --mass_slice_width
              type: double
              default: 0.1
      
          --mass_accuracy
              type: double
              default: 0.025
      
          --sigma_window_value
              type: double
              default: 0.5
      
          --amplitude_cutoff
              type: integer
              default: 10
      
          --msp_file
              type: file
              example: file.msp
      
          --ri_index_file
              type: file
              example: ri_index.txt
      
          --retention_type
              type: string
              default: RI
              choices:
                  - RI
                  - RT
      
          --ri_compound
              type: string
              default: Alkanes
              choices:
                  - Fames
                  - Alkanes
      
          --retention_time_tolerance_for_identification
              type: double
              default: 0.5
      
          --retention_index_tolerance_for_identification
              type: integer
              default: 20
      
          --ei_similarity_tolerance_for_identification
              type: integer
              default: 70
      
          --identification_score_cutoff
              type: integer
              default: 70
      
          --alignment_index_type
              type: string
              default: RT
              choices:
                  - RI
                  - RT
      
          --retention_time_tolerance_for_alignment
              type: double
              default: 0.075
      
          --retention_index_tolerance_for_alignment
              type: integer
              default: 20
      
          --ei_similarity_tolerance_for_alignment
              type: integer
              default: 70
      
          --retention_time_factor_for_alignment
              type: double
              default: 0.5
      
          --ei_similarity_factor_for_alignment
              type: double
              default: 0.5
      
          --peak_count_filter
              type: integer
              default: 0
      
          --qc_at_least_filter
              type: boolean
              default: true'''
      
      thisScript = '''set -e
      tempscript=".viash_script.sh"
      cat > "$tempscript" << VIASHMAIN
      import os
      import csv
      import re
      import tempfile
      import shutil
      import subprocess
      
      msdial_path="/msdial"
      ## VIASH START
      # The following code has been auto-generated by Viash.
      par = {
        'input': $( if [ ! -z ${VIASH_PAR_INPUT+x} ]; then echo "'${VIASH_PAR_INPUT//\\'/\\\\\\'}'.split(':')"; else echo None; fi ),
        'output': $( if [ ! -z ${VIASH_PAR_OUTPUT+x} ]; then echo "'${VIASH_PAR_OUTPUT//\\'/\\\\\\'}'"; else echo None; fi ),
        'data_type': $( if [ ! -z ${VIASH_PAR_DATA_TYPE+x} ]; then echo "'${VIASH_PAR_DATA_TYPE//\\'/\\\\\\'}'"; else echo None; fi ),
        'ion_mode': $( if [ ! -z ${VIASH_PAR_ION_MODE+x} ]; then echo "'${VIASH_PAR_ION_MODE//\\'/\\\\\\'}'"; else echo None; fi ),
        'accuracy_type': $( if [ ! -z ${VIASH_PAR_ACCURACY_TYPE+x} ]; then echo "'${VIASH_PAR_ACCURACY_TYPE//\\'/\\\\\\'}'"; else echo None; fi ),
        'retention_time_begin': $( if [ ! -z ${VIASH_PAR_RETENTION_TIME_BEGIN+x} ]; then echo "int('${VIASH_PAR_RETENTION_TIME_BEGIN//\\'/\\\\\\'}')"; else echo None; fi ),
        'retention_time_end': $( if [ ! -z ${VIASH_PAR_RETENTION_TIME_END+x} ]; then echo "int('${VIASH_PAR_RETENTION_TIME_END//\\'/\\\\\\'}')"; else echo None; fi ),
        'mass_range_begin': $( if [ ! -z ${VIASH_PAR_MASS_RANGE_BEGIN+x} ]; then echo "int('${VIASH_PAR_MASS_RANGE_BEGIN//\\'/\\\\\\'}')"; else echo None; fi ),
        'mass_range_end': $( if [ ! -z ${VIASH_PAR_MASS_RANGE_END+x} ]; then echo "int('${VIASH_PAR_MASS_RANGE_END//\\'/\\\\\\'}')"; else echo None; fi ),
        'smoothing_method': $( if [ ! -z ${VIASH_PAR_SMOOTHING_METHOD+x} ]; then echo "'${VIASH_PAR_SMOOTHING_METHOD//\\'/\\\\\\'}'"; else echo None; fi ),
        'smoothing_level': $( if [ ! -z ${VIASH_PAR_SMOOTHING_LEVEL+x} ]; then echo "int('${VIASH_PAR_SMOOTHING_LEVEL//\\'/\\\\\\'}')"; else echo None; fi ),
        'average_peak_width': $( if [ ! -z ${VIASH_PAR_AVERAGE_PEAK_WIDTH+x} ]; then echo "int('${VIASH_PAR_AVERAGE_PEAK_WIDTH//\\'/\\\\\\'}')"; else echo None; fi ),
        'minimum_peak_height': $( if [ ! -z ${VIASH_PAR_MINIMUM_PEAK_HEIGHT+x} ]; then echo "int('${VIASH_PAR_MINIMUM_PEAK_HEIGHT//\\'/\\\\\\'}')"; else echo None; fi ),
        'mass_slice_width': $( if [ ! -z ${VIASH_PAR_MASS_SLICE_WIDTH+x} ]; then echo "float('${VIASH_PAR_MASS_SLICE_WIDTH//\\'/\\\\\\'}')"; else echo None; fi ),
        'mass_accuracy': $( if [ ! -z ${VIASH_PAR_MASS_ACCURACY+x} ]; then echo "float('${VIASH_PAR_MASS_ACCURACY//\\'/\\\\\\'}')"; else echo None; fi ),
        'sigma_window_value': $( if [ ! -z ${VIASH_PAR_SIGMA_WINDOW_VALUE+x} ]; then echo "float('${VIASH_PAR_SIGMA_WINDOW_VALUE//\\'/\\\\\\'}')"; else echo None; fi ),
        'amplitude_cutoff': $( if [ ! -z ${VIASH_PAR_AMPLITUDE_CUTOFF+x} ]; then echo "int('${VIASH_PAR_AMPLITUDE_CUTOFF//\\'/\\\\\\'}')"; else echo None; fi ),
        'msp_file': $( if [ ! -z ${VIASH_PAR_MSP_FILE+x} ]; then echo "'${VIASH_PAR_MSP_FILE//\\'/\\\\\\'}'"; else echo None; fi ),
        'ri_index_file': $( if [ ! -z ${VIASH_PAR_RI_INDEX_FILE+x} ]; then echo "'${VIASH_PAR_RI_INDEX_FILE//\\'/\\\\\\'}'"; else echo None; fi ),
        'retention_type': $( if [ ! -z ${VIASH_PAR_RETENTION_TYPE+x} ]; then echo "'${VIASH_PAR_RETENTION_TYPE//\\'/\\\\\\'}'"; else echo None; fi ),
        'ri_compound': $( if [ ! -z ${VIASH_PAR_RI_COMPOUND+x} ]; then echo "'${VIASH_PAR_RI_COMPOUND//\\'/\\\\\\'}'"; else echo None; fi ),
        'retention_time_tolerance_for_identification': $( if [ ! -z ${VIASH_PAR_RETENTION_TIME_TOLERANCE_FOR_IDENTIFICATION+x} ]; then echo "float('${VIASH_PAR_RETENTION_TIME_TOLERANCE_FOR_IDENTIFICATION//\\'/\\\\\\'}')"; else echo None; fi ),
        'retention_index_tolerance_for_identification': $( if [ ! -z ${VIASH_PAR_RETENTION_INDEX_TOLERANCE_FOR_IDENTIFICATION+x} ]; then echo "int('${VIASH_PAR_RETENTION_INDEX_TOLERANCE_FOR_IDENTIFICATION//\\'/\\\\\\'}')"; else echo None; fi ),
        'ei_similarity_tolerance_for_identification': $( if [ ! -z ${VIASH_PAR_EI_SIMILARITY_TOLERANCE_FOR_IDENTIFICATION+x} ]; then echo "int('${VIASH_PAR_EI_SIMILARITY_TOLERANCE_FOR_IDENTIFICATION//\\'/\\\\\\'}')"; else echo None; fi ),
        'identification_score_cutoff': $( if [ ! -z ${VIASH_PAR_IDENTIFICATION_SCORE_CUTOFF+x} ]; then echo "int('${VIASH_PAR_IDENTIFICATION_SCORE_CUTOFF//\\'/\\\\\\'}')"; else echo None; fi ),
        'alignment_index_type': $( if [ ! -z ${VIASH_PAR_ALIGNMENT_INDEX_TYPE+x} ]; then echo "'${VIASH_PAR_ALIGNMENT_INDEX_TYPE//\\'/\\\\\\'}'"; else echo None; fi ),
        'retention_time_tolerance_for_alignment': $( if [ ! -z ${VIASH_PAR_RETENTION_TIME_TOLERANCE_FOR_ALIGNMENT+x} ]; then echo "float('${VIASH_PAR_RETENTION_TIME_TOLERANCE_FOR_ALIGNMENT//\\'/\\\\\\'}')"; else echo None; fi ),
        'retention_index_tolerance_for_alignment': $( if [ ! -z ${VIASH_PAR_RETENTION_INDEX_TOLERANCE_FOR_ALIGNMENT+x} ]; then echo "int('${VIASH_PAR_RETENTION_INDEX_TOLERANCE_FOR_ALIGNMENT//\\'/\\\\\\'}')"; else echo None; fi ),
        'ei_similarity_tolerance_for_alignment': $( if [ ! -z ${VIASH_PAR_EI_SIMILARITY_TOLERANCE_FOR_ALIGNMENT+x} ]; then echo "int('${VIASH_PAR_EI_SIMILARITY_TOLERANCE_FOR_ALIGNMENT//\\'/\\\\\\'}')"; else echo None; fi ),
        'retention_time_factor_for_alignment': $( if [ ! -z ${VIASH_PAR_RETENTION_TIME_FACTOR_FOR_ALIGNMENT+x} ]; then echo "float('${VIASH_PAR_RETENTION_TIME_FACTOR_FOR_ALIGNMENT//\\'/\\\\\\'}')"; else echo None; fi ),
        'ei_similarity_factor_for_alignment': $( if [ ! -z ${VIASH_PAR_EI_SIMILARITY_FACTOR_FOR_ALIGNMENT+x} ]; then echo "float('${VIASH_PAR_EI_SIMILARITY_FACTOR_FOR_ALIGNMENT//\\'/\\\\\\'}')"; else echo None; fi ),
        'peak_count_filter': $( if [ ! -z ${VIASH_PAR_PEAK_COUNT_FILTER+x} ]; then echo "int('${VIASH_PAR_PEAK_COUNT_FILTER//\\'/\\\\\\'}')"; else echo None; fi ),
        'qc_at_least_filter': $( if [ ! -z ${VIASH_PAR_QC_AT_LEAST_FILTER+x} ]; then echo "'${VIASH_PAR_QC_AT_LEAST_FILTER//\\'/\\\\\\'}'.lower() == 'true'"; else echo None; fi )
      }
      meta = {
        'functionality_name': '$VIASH_META_FUNCTIONALITY_NAME',
        'resources_dir': '$VIASH_META_RESOURCES_DIR',
        'temp_dir': '$VIASH_TEMP'
      }
      
      resources_dir = '$VIASH_META_RESOURCES_DIR'
      
      ## VIASH END
      
      assert len(par["input"]) > 0, "Need to specify at least one --input."
      is_dir = [ os.path.isdir(file) for file in par["input"] ]
      
      if len(par["input"]) > 1:   
         assert not any(is_dir), "Either pass to --input a single directory or a set of files."
      
      dir_mode=all(is_dir)
      
      # Create params file
      param_file = os.path.join(par["output"], "params.txt")
      ri_index_file = os.path.join(par["output"], "ri_index_paths.txt")
      
      param_content = f"""# Data type
      Data type: {par["data_type"]}
      Ion mode: {par["ion_mode"]}
      Accuracy type: {par["accuracy_type"]}
      
      # Data collection parameters
      Retention time begin: {par["retention_time_begin"]}
      Retention time end: {par["retention_time_end"]}
      Mass range begin: {par["mass_range_begin"]}
      Mass range end: {par["mass_range_end"]}
      
      # Peak detection parameters
      Smoothing method: {par["smoothing_method"]}
      Smoothing level: {par["smoothing_level"]}
      Average peak width: {par["average_peak_width"]}
      Minimum peak height: {par["minimum_peak_height"]}
      Mass slice width: {par["mass_slice_width"]}
      Mass accuracy: {par["mass_accuracy"]}
      
      # MS1Dec parameters
      Sigma window value: {par["sigma_window_value"]}
      Amplitude cut off: {par["amplitude_cutoff"]}
      
      # Identification
      {"MSP file: " + par["msp_file"] if par["msp_file"] else "# MSP file: none"}
      {"RI index file pathes: " + ri_index_file if par["ri_index_file"] else "# RI index file pathes: none"}
      Retention type: {par["retention_type"]}
      RI compound: {par["ri_compound"]}
      Retention time tolerance for identification: {par["retention_time_tolerance_for_identification"]}
      Retention index tolerance for identification: {par["retention_index_tolerance_for_identification"]}
      EI similarity tolerance for identification: {par["ei_similarity_tolerance_for_identification"]}
      Identification score cut off: {par["identification_score_cutoff"]}
      
      # Alignment parameters setting
      Alignment index type: {par["alignment_index_type"]}
      Retention time tolerance for alignment: {par["retention_time_tolerance_for_alignment"]}
      Retention index tolerance for alignment: {par["retention_index_tolerance_for_alignment"]}
      EI similarity tolerance for alignment: {par["ei_similarity_tolerance_for_alignment"]}
      Retention time factor for alignment: {par["retention_time_factor_for_alignment"]}
      EI similarity factor for alignment: {par["ei_similarity_factor_for_alignment"]}
      Peak count filter: {par["peak_count_filter"]}
      QC at least filter: {par["qc_at_least_filter"]}
      """
      
      with tempfile.TemporaryDirectory() as temp_dir:
         # copy input files to tempdir
         # because MSDial otherwise generates a lot
         # of temporary files in the input dir.
         if dir_mode:
            shutil.copytree(par["input"][0], temp_dir, dirs_exist_ok=True)
         else:
            for file in par["input"]:
               dest = os.path.join(temp_dir, os.path.basename(file))
               print(f"Copying {file} to {dest}")
               shutil.copyfile(file, dest)
      
         # create output dir if not exists
         if not os.path.exists(par["output"]):
            os.makedirs(par["output"])
         
         # create ri index file paths file
         # (if needed)
         if par["ri_index_file"]:
            with open(ri_index_file, 'w') as out_file:
               tsv_writer = csv.writer(out_file, delimiter="\\\\t")
      
               for top, dirs, files in os.walk(temp_dir):
                  input_files = [ os.path.join(top, file) for file in files if re.match('.*\\\\.(abf|cdf|mzml|ibf|wiff|wiff2|raw|d)\\$', file)]
                  tsv_writer.writerows([[file, par["ri_index_file"]] for file in input_files])
      
         # write params file
         with open(param_file, "w") as f:
            f.write(param_content)
      
         # run msdial
         p = subprocess.Popen(
            [
               f"{msdial_path}/MsdialConsoleApp", 
               "gcms", 
               "-i", temp_dir,
               "-o", par["output"],
               "-m", param_file,
               "-p"
            ]
         )
         p.wait()
      
      if p.returncode != 0:
         raise Exception(f"MS-DIAL finished with exit code {p.returncode}") 
      VIASHMAIN
      python "$tempscript"
      '''
      
      thisDefaultProcessArgs = [
        // key to be used to trace the process and determine output names
        key: thisFunctionality.name,
        // fixed arguments to be passed to script
        args: [:],
        // default directives
        directives: jsonSlurper.parseText("""{
        "container" : {
          "registry" : "ghcr.io",
          "image" : "czbiohub/mspipelines/msdial_msdial_gcms",
          "tag" : "main_build"
        }
      }"""),
        // auto settings
        auto: jsonSlurper.parseText("""{
        "simplifyInput" : true,
        "simplifyOutput" : true,
        "transcript" : false,
        "publish" : false
      }"""),
        // apply a map over the incoming tuple
        // example: { tup -> [ tup[0], [input: tup[1].output], tup[2] ] }
        map: null,
        // apply a map over the ID element of a tuple (i.e. the first element)
        // example: { id -> id + "_foo" }
        mapId: null,
        // apply a map over the data element of a tuple (i.e. the second element)
        // example: { data -> [ input: data.output ] }
        mapData: null,
        // apply a map over the passthrough elements of a tuple (i.e. the tuple excl. the first two elements)
        // example: { pt -> pt.drop(1) }
        mapPassthrough: null,
        // rename keys in the data field of the tuple (i.e. the second element)
        // example: [ "new_key": "old_key" ]
        renameKeys: null,
        // whether or not to print debug messages
        debug: false
      ]
      
      // END CUSTOM CODE
      
      import nextflow.Nextflow
      import nextflow.script.IncludeDef
      import nextflow.script.ScriptBinding
      import nextflow.script.ScriptMeta
      import nextflow.script.ScriptParser
      
      // retrieve resourcesDir here to make sure the correct path is found
      resourcesDir = ScriptMeta.current().getScriptPath().getParent()
      
      def assertMapKeys(map, expectedKeys, requiredKeys, mapName) {
        assert map instanceof Map : "Expected argument '$mapName' to be a Map. Found: class ${map.getClass()}"
        map.forEach { key, val -> 
          assert key in expectedKeys : "Unexpected key '$key' in ${mapName ? mapName + " " : ""}map"
        }
        requiredKeys.forEach { requiredKey -> 
          assert map.containsKey(requiredKey) : "Missing required key '$key' in ${mapName ? mapName + " " : ""}map"
        }
      }
      
      // TODO: unit test processDirectives
      def processDirectives(Map drctv) {
        // remove null values
        drctv = drctv.findAll{k, v -> v != null}
      
        /* DIRECTIVE accelerator
          accepted examples:
          - [ limit: 4, type: "nvidia-tesla-k80" ]
        */
        if (drctv.containsKey("accelerator")) {
          assertMapKeys(drctv["accelerator"], ["type", "limit", "request", "runtime"], [], "accelerator")
        }
      
        /* DIRECTIVE afterScript
          accepted examples:
          - "source /cluster/bin/cleanup"
        */
        if (drctv.containsKey("afterScript")) {
          assert drctv["afterScript"] instanceof CharSequence
        }
      
        /* DIRECTIVE beforeScript
          accepted examples:
          - "source /cluster/bin/setup"
        */
        if (drctv.containsKey("beforeScript")) {
          assert drctv["beforeScript"] instanceof CharSequence
        }
      
        /* DIRECTIVE cache
          accepted examples:
          - true
          - false
          - "deep"
          - "lenient"
        */
        if (drctv.containsKey("cache")) {
          assert drctv["cache"] instanceof CharSequence || drctv["cache"] instanceof Boolean
          if (drctv["cache"] instanceof CharSequence) {
            assert drctv["cache"] in ["deep", "lenient"] : "Unexpected value for cache"
          }
        }
      
        /* DIRECTIVE conda
          accepted examples:
          - "bwa=0.7.15"
          - "bwa=0.7.15 fastqc=0.11.5"
          - ["bwa=0.7.15", "fastqc=0.11.5"]
        */
        if (drctv.containsKey("conda")) {
          if (drctv["conda"] instanceof List) {
            drctv["conda"] = drctv["conda"].join(" ")
          }
          assert drctv["conda"] instanceof CharSequence
        }
      
        /* DIRECTIVE container
          accepted examples:
          - "foo/bar:tag"
          - [ registry: "reg", image: "im", tag: "ta" ]
            is transformed to "reg/im:ta"
          - [ image: "im" ] 
            is transformed to "im:latest"
        */
        if (drctv.containsKey("container")) {
          assert drctv["container"] instanceof Map || drctv["container"] instanceof CharSequence
          if (drctv["container"] instanceof Map) {
            def m = drctv["container"]
            assertMapKeys(m, [ "registry", "image", "tag" ], ["image"], "container")
            def part1 = m.registry ? m.registry + "/" : ""
            def part2 = m.image
            def part3 = m.tag ? ":" + m.tag : ":latest"
            drctv["container"] = part1 + part2 + part3
          }
        }
      
        /* DIRECTIVE containerOptions
          accepted examples:
          - "--foo bar"
          - ["--foo bar", "-f b"]
        */
        if (drctv.containsKey("containerOptions")) {
          if (drctv["containerOptions"] instanceof List) {
            drctv["containerOptions"] = drctv["containerOptions"].join(" ")
          }
          assert drctv["containerOptions"] instanceof CharSequence
        }
      
        /* DIRECTIVE cpus
          accepted examples:
          - 1
          - 10
        */
        if (drctv.containsKey("cpus")) {
          assert drctv["cpus"] instanceof Integer
        }
      
        /* DIRECTIVE disk
          accepted examples:
          - "1 GB"
          - "2TB"
          - "3.2KB"
          - "10.B"
        */
        if (drctv.containsKey("disk")) {
          assert drctv["disk"] instanceof CharSequence
          // assert drctv["disk"].matches("[0-9]+(\\.[0-9]*)? *[KMGTPEZY]?B")
          // ^ does not allow closures
        }
      
        /* DIRECTIVE echo
          accepted examples:
          - true
          - false
        */
        if (drctv.containsKey("echo")) {
          assert drctv["echo"] instanceof Boolean
        }
      
        /* DIRECTIVE errorStrategy
          accepted examples:
          - "terminate"
          - "finish"
        */
        if (drctv.containsKey("errorStrategy")) {
          assert drctv["errorStrategy"] instanceof CharSequence
          assert drctv["errorStrategy"] in ["terminate", "finish", "ignore", "retry"] : "Unexpected value for errorStrategy"
        }
      
        /* DIRECTIVE executor
          accepted examples:
          - "local"
          - "sge"
        */
        if (drctv.containsKey("executor")) {
          assert drctv["executor"] instanceof CharSequence
          assert drctv["executor"] in ["local", "sge", "uge", "lsf", "slurm", "pbs", "pbspro", "moab", "condor", "nqsii", "ignite", "k8s", "awsbatch", "google-pipelines"] : "Unexpected value for executor"
        }
      
        /* DIRECTIVE machineType
          accepted examples:
          - "n1-highmem-8"
        */
        if (drctv.containsKey("machineType")) {
          assert drctv["machineType"] instanceof CharSequence
        }
      
        /* DIRECTIVE maxErrors
          accepted examples:
          - 1
          - 3
        */
        if (drctv.containsKey("maxErrors")) {
          assert drctv["maxErrors"] instanceof Integer
        }
      
        /* DIRECTIVE maxForks
          accepted examples:
          - 1
          - 3
        */
        if (drctv.containsKey("maxForks")) {
          assert drctv["maxForks"] instanceof Integer
        }
      
        /* DIRECTIVE maxRetries
          accepted examples:
          - 1
          - 3
        */
        if (drctv.containsKey("maxRetries")) {
          assert drctv["maxRetries"] instanceof Integer
        }
      
        /* DIRECTIVE memory
          accepted examples:
          - "1 GB"
          - "2TB"
          - "3.2KB"
          - "10.B"
        */
        if (drctv.containsKey("memory")) {
          assert drctv["memory"] instanceof CharSequence
          // assert drctv["memory"].matches("[0-9]+(\\.[0-9]*)? *[KMGTPEZY]?B")
          // ^ does not allow closures
        }
      
        /* DIRECTIVE module
          accepted examples:
          - "ncbi-blast/2.2.27"
          - "ncbi-blast/2.2.27:t_coffee/10.0"
          - ["ncbi-blast/2.2.27", "t_coffee/10.0"]
        */
        if (drctv.containsKey("module")) {
          if (drctv["module"] instanceof List) {
            drctv["module"] = drctv["module"].join(":")
          }
          assert drctv["module"] instanceof CharSequence
        }
      
        /* DIRECTIVE penv
          accepted examples:
          - "smp"
        */
        if (drctv.containsKey("penv")) {
          assert drctv["penv"] instanceof CharSequence
        }
      
        /* DIRECTIVE pod
          accepted examples:
          - [ label: "key", value: "val" ]
          - [ annotation: "key", value: "val" ]
          - [ env: "key", value: "val" ]
          - [ [label: "l", value: "v"], [env: "e", value: "v"]]
        */
        if (drctv.containsKey("pod")) {
          if (drctv["pod"] instanceof Map) {
            drctv["pod"] = [ drctv["pod"] ]
          }
          assert drctv["pod"] instanceof List
          drctv["pod"].forEach { pod ->
            assert pod instanceof Map
            // TODO: should more checks be added?
            // See https://www.nextflow.io/docs/latest/process.html?highlight=directives#pod
            // e.g. does it contain 'label' and 'value', or 'annotation' and 'value', or ...?
          }
        }
      
        /* DIRECTIVE publishDir
          accepted examples:
          - []
          - [ [ path: "foo", enabled: true ], [ path: "bar", enabled: false ] ]
          - "/path/to/dir" 
            is transformed to [[ path: "/path/to/dir" ]]
          - [ path: "/path/to/dir", mode: "cache" ]
            is transformed to [[ path: "/path/to/dir", mode: "cache" ]]
        */
        // TODO: should we also look at params["publishDir"]?
        if (drctv.containsKey("publishDir")) {
          def pblsh = drctv["publishDir"]
          
          // check different options
          assert pblsh instanceof List || pblsh instanceof Map || pblsh instanceof CharSequence
          
          // turn into list if not already so
          // for some reason, 'if (!pblsh instanceof List) pblsh = [ pblsh ]' doesn't work.
          pblsh = pblsh instanceof List ? pblsh : [ pblsh ]
      
          // check elements of publishDir
          pblsh = pblsh.collect{ elem ->
            // turn into map if not already so
            elem = elem instanceof CharSequence ? [ path: elem ] : elem
      
            // check types and keys
            assert elem instanceof Map : "Expected publish argument '$elem' to be a String or a Map. Found: class ${elem.getClass()}"
            assertMapKeys(elem, [ "path", "mode", "overwrite", "pattern", "saveAs", "enabled" ], ["path"], "publishDir")
      
            // check elements in map
            assert elem.containsKey("path")
            assert elem["path"] instanceof CharSequence
            if (elem.containsKey("mode")) {
              assert elem["mode"] instanceof CharSequence
              assert elem["mode"] in [ "symlink", "rellink", "link", "copy", "copyNoFollow", "move" ]
            }
            if (elem.containsKey("overwrite")) {
              assert elem["overwrite"] instanceof Boolean
            }
            if (elem.containsKey("pattern")) {
              assert elem["pattern"] instanceof CharSequence
            }
            if (elem.containsKey("saveAs")) {
              assert elem["saveAs"] instanceof CharSequence //: "saveAs as a Closure is currently not supported. Surround your closure with single quotes to get the desired effect. Example: '\{ foo \}'"
            }
            if (elem.containsKey("enabled")) {
              assert elem["enabled"] instanceof Boolean
            }
      
            // return final result
            elem
          }
          // store final directive
          drctv["publishDir"] = pblsh
        }
      
        /* DIRECTIVE queue
          accepted examples:
          - "long"
          - "short,long"
          - ["short", "long"]
        */
        if (drctv.containsKey("queue")) {
          if (drctv["queue"] instanceof List) {
            drctv["queue"] = drctv["queue"].join(",")
          }
          assert drctv["queue"] instanceof CharSequence
        }
      
        /* DIRECTIVE label
          accepted examples:
          - "big_mem"
          - "big_cpu"
          - ["big_mem", "big_cpu"]
        */
        if (drctv.containsKey("label")) {
          if (drctv["label"] instanceof CharSequence) {
            drctv["label"] = [ drctv["label"] ]
          }
          assert drctv["label"] instanceof List
          drctv["label"].forEach { label ->
            assert label instanceof CharSequence
            // assert label.matches("[a-zA-Z0-9]([a-zA-Z0-9_]*[a-zA-Z0-9])?")
            // ^ does not allow closures
          }
        }
      
        /* DIRECTIVE scratch
          accepted examples:
          - true
          - "/path/to/scratch"
          - '$MY_PATH_TO_SCRATCH'
          - "ram-disk"
        */
        if (drctv.containsKey("scratch")) {
          assert drctv["scratch"] == true || drctv["scratch"] instanceof CharSequence
        }
      
        /* DIRECTIVE storeDir
          accepted examples:
          - "/path/to/storeDir"
        */
        if (drctv.containsKey("storeDir")) {
          assert drctv["storeDir"] instanceof CharSequence
        }
      
        /* DIRECTIVE stageInMode
          accepted examples:
          - "copy"
          - "link"
        */
        if (drctv.containsKey("stageInMode")) {
          assert drctv["stageInMode"] instanceof CharSequence
          assert drctv["stageInMode"] in ["copy", "link", "symlink", "rellink"]
        }
      
        /* DIRECTIVE stageOutMode
          accepted examples:
          - "copy"
          - "link"
        */
        if (drctv.containsKey("stageOutMode")) {
          assert drctv["stageOutMode"] instanceof CharSequence
          assert drctv["stageOutMode"] in ["copy", "move", "rsync"]
        }
      
        /* DIRECTIVE tag
          accepted examples:
          - "foo"
          - '$id'
        */
        if (drctv.containsKey("tag")) {
          assert drctv["tag"] instanceof CharSequence
        }
      
        /* DIRECTIVE time
          accepted examples:
          - "1h"
          - "2days"
          - "1day 6hours 3minutes 30seconds"
        */
        if (drctv.containsKey("time")) {
          assert drctv["time"] instanceof CharSequence
          // todo: validation regex?
        }
      
        return drctv
      }
      
      // TODO: unit test processAuto
      def processAuto(Map auto) {
        // remove null values
        auto = auto.findAll{k, v -> v != null}
      
        expectedKeys = ["simplifyInput", "simplifyOutput", "transcript", "publish"]
      
        // check whether expected keys are all booleans (for now)
        for (key in expectedKeys) {
          assert auto.containsKey(key)
          assert auto[key] instanceof Boolean
        }
      
        return auto.subMap(expectedKeys)
      }
      
      def processProcessArgs(Map args) {
        // override defaults with args
        def processArgs = thisDefaultProcessArgs + args
      
        // check whether 'key' exists
        assert processArgs.containsKey("key")
      
        // if 'key' is a closure, apply it to the original key
        if (processArgs["key"] instanceof Closure) {
          processArgs["key"] = processArgs["key"](thisFunctionality.name)
        }
        assert processArgs["key"] instanceof CharSequence
        assert processArgs["key"] ==~ /^[a-zA-Z_][a-zA-Z0-9_]*$/
      
        // check whether directives exists and apply defaults
        assert processArgs.containsKey("directives")
        assert processArgs["directives"] instanceof Map
        processArgs["directives"] = processDirectives(thisDefaultProcessArgs.directives + processArgs["directives"])
      
        // check whether directives exists and apply defaults
        assert processArgs.containsKey("auto")
        assert processArgs["auto"] instanceof Map
        processArgs["auto"] = processAuto(thisDefaultProcessArgs.auto + processArgs["auto"])
      
        // auto define publish, if so desired
        if (processArgs.auto.publish == true && (processArgs.directives.publishDir ?: [:]).isEmpty()) {
          assert params.containsKey("publishDir") : 
            "Error in module '${processArgs['key']}': if auto.publish is true, params.publishDir needs to be defined.\n" +
            "  Example: params.transcriptsDir = \"./output/\""
          
          // TODO: more asserts on publishDir?
          processArgs.directives.publishDir = [[ 
            path: params.publishDir, 
            saveAs: "{ it.startsWith('.') ? null : it }", // don't publish hidden files, by default
            mode: "copy"
          ]]
        }
      
        // auto define transcript, if so desired
        if (processArgs.auto.transcript == true) {
          assert params.containsKey("transcriptsDir") || params.containsKey("publishDir") : 
            "Error in module '${processArgs['key']}': if auto.transcript is true, either params.transcriptsDir or params.publishDir needs to be defined.\n" +
            "  Example: params.transcriptsDir = \"./transcripts/\""
          def transcriptsDir = params.containsKey("transcriptsDir") ? params.transcriptsDir : params.publishDir + "/_transcripts"
          def timestamp = Nextflow.getSession().getWorkflowMetadata().start.format('yyyy-MM-dd_HH-mm-ss')
          def transcriptsPublishDir = [ 
            path: "$transcriptsDir/$timestamp/\${task.process.replaceAll(':', '-')}/\${id}/", 
            saveAs: "{ it.startsWith('.') ? it.replaceAll('^.', '') : null }", 
            mode: "copy"
          ]
          def publishDirs = processArgs.directives.publishDir ?: []
          processArgs.directives.publishDir = publishDirs + transcriptsPublishDir
        }
      
        for (nam in [ "map", "mapId", "mapData", "mapPassthrough" ]) {
          if (processArgs.containsKey(nam) && processArgs[nam]) {
            assert processArgs[nam] instanceof Closure : "Expected process argument '$nam' to be null or a Closure. Found: class ${processArgs[nam].getClass()}"
          }
        }
      
        // return output
        return processArgs
      }
      
      def processFactory(Map processArgs) {
        def tripQuo = "\"\"\""
      
        // autodetect process key
        def wfKey = processArgs["key"]
        def procKeyPrefix = "${wfKey}_process"
        def meta = ScriptMeta.current()
        def existing = meta.getProcessNames().findAll{it.startsWith(procKeyPrefix)}
        def numbers = existing.collect{it.replace(procKeyPrefix, "0").toInteger()}
        def newNumber = (numbers + [-1]).max() + 1
      
        def procKey = newNumber == 0 ? procKeyPrefix : "$procKeyPrefix$newNumber"
      
        if (newNumber > 0) {
          log.warn "Key for module '${wfKey}' is duplicated.\n",
            "If you run a component multiple times in the same workflow,\n" +
            "it's recommended you set a unique key for every call,\n" +
            "for example: ${wfKey}.run(key: \"foo\")."
        }
      
        // subset directives and convert to list of tuples
        def drctv = processArgs.directives
      
        // TODO: unit test the two commands below
        // convert publish array into tags
        def valueToStr = { val ->
          // ignore closures
          if (val instanceof CharSequence) {
            if (!val.matches('^[{].*[}]$')) {
              '"' + val + '"'
            } else {
              val
            }
          } else if (val instanceof List) {
            "[" + val.collect{valueToStr(it)}.join(", ") + "]"
          } else if (val instanceof Map) {
            "[" + val.collect{k, v -> k + ": " + valueToStr(v)}.join(", ") + "]"
          } else {
            val.inspect()
          }
        }
        // multiple entries allowed: label, publishdir
        def drctvStrs = drctv.collect { key, value ->
          if (key in ["label", "publishDir"]) {
            value.collect{ val ->
              if (val instanceof Map) {
                "\n$key " + val.collect{ k, v -> k + ": " + valueToStr(v) }.join(", ")
              } else {
                "\n$key " + valueToStr(val)
              }
            }.join()
          } else if (value instanceof Map) {
            "\n$key " + value.collect{ k, v -> k + ": " + valueToStr(v) }.join(", ")
          } else {
            "\n$key " + valueToStr(value)
          }
        }.join()
      
        def inputPaths = thisFunctionality.arguments
          .findAll { it.type == "file" && it.direction == "input" }
          .collect { ', path(viash_par_' + it.name + ')' }
          .join()
      
        def outputPaths = thisFunctionality.arguments
          .findAll { it.type == "file" && it.direction == "output" }
          .collect { par ->
            // insert dummy into every output (see nextflow-io/nextflow#2678)
            if (!par.multiple) {
              ', path{[".exitcode", args.' + par.name + ']}'
            } else {
              ', path{[".exitcode"] + args.' + par.name + '}'
            }
          }
          .join()
      
        // TODO: move this functionality somewhere else?
        if (processArgs.auto.transcript) {
          outputPaths = outputPaths + ', path{[".exitcode", ".command*"]}'
        } else {
          outputPaths = outputPaths + ', path{[".exitcode"]}'
        }
      
        // construct inputFileExports
        def inputFileExports = thisFunctionality.arguments
          .findAll { it.type == "file" && it.direction.toLowerCase() == "input" }
          .collect { par ->
            if (!par.required && !par.multiple) {
              "\n\${viash_par_${par.name}.empty ? \"\" : \"export VIASH_PAR_${par.name.toUpperCase()}=\\\"\" + viash_par_${par.name}[0] + \"\\\"\"}"
            } else {
              "\nexport VIASH_PAR_${par.name.toUpperCase()}=\"\${viash_par_${par.name}.join(\":\")}\""
            }
          }
        
        def tmpDir = "/tmp" // check if component is docker based
      
        // construct stub
        def stub = thisFunctionality.arguments
          .findAll { it.type == "file" && it.direction == "output" }
          .collect { par -> 
            'touch "${viash_par_' + par.name + '.join(\'" "\')}"'
          }
          .join("\n")
      
        // escape script
        def escapedScript = thisScript.replace('\\', '\\\\').replace('$', '\\$').replace('"""', '\\"\\"\\"')
      
        // generate process string
        def procStr = 
        """nextflow.enable.dsl=2
        |
        |process $procKey {$drctvStrs
        |input:
        |  tuple val(id)$inputPaths, val(args), val(passthrough), path(resourcesDir)
        |output:
        |  tuple val("\$id"), val(passthrough)$outputPaths, optional: true
        |stub:
        |$tripQuo
        |$stub
        |$tripQuo
        |script:
        |def escapeText = { s -> s.toString().replaceAll('([`"])', '\\\\\\\\\$1') }
        |def parInject = args
        |  .findAll{key, value -> value != null}
        |  .collect{key, value -> "export VIASH_PAR_\${key.toUpperCase()}=\\\"\${escapeText(value)}\\\""}
        |  .join("\\n")
        |$tripQuo
        |# meta exports
        |export VIASH_META_RESOURCES_DIR="\$resourcesDir"
        |export VIASH_META_TEMP_DIR="${tmpDir}"
        |export VIASH_META_FUNCTIONALITY_NAME="${thisFunctionality.name}"
        |
        |# meta synonyms
        |export VIASH_RESOURCES_DIR="\\\$VIASH_META_RESOURCES_DIR"
        |export VIASH_TEMP="\\\$VIASH_META_TEMP_DIR"
        |export TEMP_DIR="\\\$VIASH_META_TEMP_DIR"
        |
        |# argument exports${inputFileExports.join()}
        |\$parInject
        |
        |# process script
        |${escapedScript}
        |$tripQuo
        |}
        |""".stripMargin()
      
        // TODO: print on debug
        // if (processArgs.debug == true) {
        //   println("######################\n$procStr\n######################")
        // }
      
        // create runtime process
        def ownerParams = new ScriptBinding.ParamsMap()
        def binding = new ScriptBinding().setParams(ownerParams)
        def module = new IncludeDef.Module(name: procKey)
        def moduleScript = new ScriptParser(session)
          .setModule(true)
          .setBinding(binding)
          .runScript(procStr)
          .getScript()
      
        // register module in meta
        meta.addModule(moduleScript, module.name, module.alias)
      
        // retrieve and return process from meta
        return meta.getProcess(procKey)
      }
      
      def debug(processArgs, debugKey) {
        if (processArgs.debug) {
          view { "process '${processArgs.key}' $debugKey tuple: $it"  }
        } else {
          map { it }
        }
      }
      
      // wfKeyCounter = -1
      
      def workflowFactory(Map args) {
        def processArgs = processProcessArgs(args)
        def key = processArgs["key"]
        def meta = ScriptMeta.current()
      
        // def workflowKey = wfKeyCounter == -1 ? key : "$key$wfKeyCounter"
        // wfKeyCounter++
        def workflowKey = key
      
        // write process to temporary nf file and parse it in memory
        def processObj = processFactory(processArgs)
        
        workflow workflowInstance {
          take:
          input_
      
          main:
          output_ = input_
            | debug(processArgs, "input")
            | map { tuple ->
              if (processArgs.map) {
                tuple = processArgs.map(tuple)
              }
              if (processArgs.mapId) {
                tuple[0] = processArgs.mapId(tuple[0])
              }
              if (processArgs.mapData) {
                tuple[1] = processArgs.mapData(tuple[1])
              }
              if (processArgs.mapPassthrough) {
                tuple = tuple.take(2) + processArgs.mapPassthrough(tuple.drop(2))
              }
      
              // check tuple
              assert tuple instanceof List : 
                "Error in module '${key}': element in channel should be a tuple [id, data, ...otherargs...]\n" +
                "  Example: [\"id\", [input: file('foo.txt'), arg: 10]].\n" +
                "  Expected class: List. Found: tuple.getClass() is ${tuple.getClass()}"
              assert tuple.size() >= 2 : 
                "Error in module '${key}': expected length of tuple in input channel to be two or greater.\n" +
                "  Example: [\"id\", [input: file('foo.txt'), arg: 10]].\n" +
                "  Found: tuple.size() == ${tuple.size()}"
              
              // check id field
              assert tuple[0] instanceof CharSequence : 
                "Error in module '${key}': first element of tuple in channel should be a String\n" +
                "  Example: [\"id\", [input: file('foo.txt'), arg: 10]].\n" +
                "  Found: ${tuple[0]}"
              
              // match file to input file
              if (processArgs.auto.simplifyInput && tuple[1] instanceof Path) {
                def inputFiles = thisFunctionality.arguments
                  .findAll { it.type == "file" && it.direction == "input" }
                
                assert inputFiles.size() == 1 : 
                    "Error in module '${key}' id '${tuple[0]}'.\n" +
                    "  Anonymous file inputs are only allowed when the process has exactly one file input.\n" +
                    "  Expected: inputFiles.size() == 1. Found: inputFiles.size() is ${inputFiles.size()}"
      
                tuple[1] = [[ inputFiles[0].name, tuple[1] ]].collectEntries()
              }
      
              // check data field
              assert tuple[1] instanceof Map : 
                "Error in module '${key}' id '${tuple[0]}': second element of tuple in channel should be a Map\n" +
                "  Example: [\"id\", [input: file('foo.txt'), arg: 10]].\n" +
                "  Expected class: Map. Found: tuple[1].getClass() is ${tuple[1].getClass()}"
      
              // rename keys of data field in tuple
              if (processArgs.renameKeys) {
                assert processArgs.renameKeys instanceof Map : 
                    "Error renaming data keys in module '${key}' id '${tuple[0]}'.\n" +
                    "  Example: renameKeys: ['new_key': 'old_key'].\n" +
                    "  Expected class: Map. Found: renameKeys.getClass() is ${processArgs.renameKeys.getClass()}"
                assert tuple[1] instanceof Map : 
                    "Error renaming data keys in module '${key}' id '${tuple[0]}'.\n" +
                    "  Expected class: Map. Found: tuple[1].getClass() is ${tuple[1].getClass()}"
      
                // TODO: allow renameKeys to be a function?
                processArgs.renameKeys.each { newKey, oldKey ->
                  assert newKey instanceof CharSequence : 
                    "Error renaming data keys in module '${key}' id '${tuple[0]}'.\n" +
                    "  Example: renameKeys: ['new_key': 'old_key'].\n" +
                    "  Expected class of newKey: String. Found: newKey.getClass() is ${newKey.getClass()}"
                  assert oldKey instanceof CharSequence : 
                    "Error renaming data keys in module '${key}' id '${tuple[0]}'.\n" +
                    "  Example: renameKeys: ['new_key': 'old_key'].\n" +
                    "  Expected class of oldKey: String. Found: oldKey.getClass() is ${oldKey.getClass()}"
                  assert tuple[1].containsKey(oldKey) : 
                    "Error renaming data keys in module '${key}' id '${tuple[0]}'.\n" +
                    "  Key '$oldKey' is missing in the data map. tuple[1].keySet() is '${tuple[1].keySet()}'"
                  tuple[1].put(newKey, tuple[1][oldKey])
                }
                tuple[1].keySet().removeAll(processArgs.renameKeys.collect{ newKey, oldKey -> oldKey })
              }
              tuple
            }
            | debug(processArgs, "processed")
            | map { tuple ->
              def id = tuple[0]
              def data = tuple[1]
              def passthrough = tuple.drop(2)
      
              // fetch default params from functionality
              def defaultArgs = thisFunctionality.arguments
                .findAll { it.containsKey("default") }
                .collectEntries { [ it.name, it.default ] }
      
              // fetch overrides in params
              def paramArgs = thisFunctionality.arguments
                .findAll { par ->
                  def argKey = key + "__" + par.name
                  params.containsKey(argKey) && params[argKey] != "viash_no_value"
                }
                .collectEntries { [ it.name, params[key + "__" + it.name] ] }
              
              // fetch overrides in data
              def dataArgs = thisFunctionality.arguments
                .findAll { data.containsKey(it.name) }
                .collectEntries { [ it.name, data[it.name] ] }
              
              // combine params
              def combinedArgs = defaultArgs + paramArgs + processArgs.args + dataArgs
      
              // remove arguments with explicit null values
              combinedArgs.removeAll{it == null}
      
              // check whether required arguments exist
              thisFunctionality.arguments
                .forEach { par ->
                  if (par.required) {
                    assert combinedArgs.containsKey(par.name): "Argument ${par.name} is required but does not have a value"
                  }
                }
      
              // TODO: check whether parameters have the right type
      
              // process input files separately
              def inputPaths = thisFunctionality.arguments
                .findAll { it.type == "file" && it.direction == "input" }
                .collect { par ->
                  def val = combinedArgs.containsKey(par.name) ? combinedArgs[par.name] : []
                  def inputFiles = []
                  if (val == null) {
                    inputFiles = []
                  } else if (val instanceof List) {
                    inputFiles = val
                  } else if (val instanceof Path) {
                    inputFiles = [ val ]
                  } else {
                    inputFiles = []
                  }
                  // throw error when an input file doesn't exist
                  inputFiles.each{ file -> 
                    assert file.exists() :
                      "Error in module '${key}' id '${id}' argument '${par.name}'.\n" +
                      "  Required input file does not exist.\n" +
                      "  Path: '$file'.\n" +
                      "  Expected input file to exist"
                  }
                  inputFiles 
                } 
      
              // remove input files
              def argsExclInputFiles = thisFunctionality.arguments
                .findAll { it.type != "file" || it.direction != "input" }
                .collectEntries { par ->
                  def parName = par.name
                  def val = combinedArgs[parName]
                  if (par.multiple && val instanceof Collection) {
                    val = val.join(par.multiple_sep)
                  }
                  if (par.direction == "output" && par.type == "file") {
                    val = val.replaceAll('\\$id', id).replaceAll('\\$key', key)
                  }
                  [parName, val]
                }
      
              [ id ] + inputPaths + [ argsExclInputFiles, passthrough, resourcesDir ]
            }
            | processObj
            | map { output ->
              def outputFiles = thisFunctionality.arguments
                .findAll { it.type == "file" && it.direction == "output" }
                .indexed()
                .collectEntries{ index, par ->
                  out = output[index + 2]
                  // strip dummy '.exitcode' file from output (see nextflow-io/nextflow#2678)
                  if (!out instanceof List || out.size() <= 1) {
                    if (par.multiple) {
                      out = []
                    } else {
                      assert !par.required :
                          "Error in module '${key}' id '${output[0]}' argument '${par.name}'.\n" +
                          "  Required output file is missing"
                      out = null
                    }
                  } else if (out.size() == 2 && !par.multiple) {
                    out = out[1]
                  } else {
                    out = out.drop(1)
                  }
                  [ par.name, out ]
                }
              
              // drop null outputs
              outputFiles.removeAll{it.value == null}
      
              if (processArgs.auto.simplifyOutput && outputFiles.size() == 1) {
                outputFiles = outputFiles.values()[0]
              }
      
              def out = [ output[0], outputFiles ]
      
              // passthrough additional items
              if (output[1]) {
                out.addAll(output[1])
              }
      
              out
            }
            | debug(processArgs, "output")
      
          emit:
          output_
        }
      
        def wf = workflowInstance.cloneWithName(workflowKey)
      
        // add factory function
        wf.metaClass.run = { runArgs ->
          workflowFactory(runArgs)
        }
      
        return wf
      }
      
      // initialise default workflow
      myWfInstance = workflowFactory([:])
      
      // add workflow to environment
      ScriptMeta.current().addDefinition(myWfInstance)
      
      // anonymous workflow for running this module as a standalone
      workflow {
        if (params.containsKey("help") && params["help"]) {
          exit 0, thisHelpMessage
        }
        if (!params.containsKey("id")) {
          params.id = "run"
        }
        if (!params.containsKey("publishDir")) {
          params.publishDir = "./"
        }
      
        // fetch parameters
        def args = thisFunctionality.arguments
          .findAll { par -> params.containsKey(par.name) }
          .collectEntries { par ->
            if (par.type == "file" && par.direction == "input") {
              [ par.name, file(params[par.name]) ]
            } else {
              [ par.name, params[par.name] ]
            }
          }
                
        Channel.value([ params.id, args ])
          | view { "input: $it" }
          | myWfInstance.run(
            auto: [ publish: true ]
          )
          | view { "output: $it" }
      }

    dest: "main.nf"
  - type: "file"
    text: |
      manifest {
        name = 'msdial_gcms'
        mainScript = 'main.nf'
        nextflowVersion = '!>=20.12.1-edge'
        version = 'main_build'
        author = 'Robrecht Cannoodt <rcannood@gmail.com> (maintainer) {github: rcannood, orcid: 0000-0003-3641-729X}'
      }
      
      // detect tempdir
      tempDir = java.nio.file.Paths.get(
        System.getenv('NXF_TEMP') ?:
          System.getenv('VIASH_TEMP') ?: 
          System.getenv('TEMPDIR') ?: 
          System.getenv('TMPDIR') ?: 
          '/tmp'
      ).toAbsolutePath()
      
      profiles {
        docker {
          docker.enabled         = true
          docker.userEmulation   = true
          docker.temp            = tempDir
          singularity.enabled    = false
          podman.enabled         = false
          shifter.enabled        = false
          charliecloud.enabled   = false
        }
        singularity {
          singularity.enabled    = true
          singularity.autoMounts = true
          docker.enabled         = false
          podman.enabled         = false
          shifter.enabled        = false
          charliecloud.enabled   = false
        }
        podman {
          podman.enabled         = true
          podman.temp            = tempDir
          docker.enabled         = false
          singularity.enabled    = false
          shifter.enabled        = false
          charliecloud.enabled   = false
        }
        shifter {
          shifter.enabled        = true
          docker.enabled         = false
          singularity.enabled    = false
          podman.enabled         = false
          charliecloud.enabled   = false
        }
        charliecloud {
          charliecloud.enabled   = true
          charliecloud.temp      = tempDir
          docker.enabled         = false
          singularity.enabled    = false
          podman.enabled         = false
          shifter.enabled        = false
        }
      }

    dest: "nextflow.config"
  tests:
  - type: "bash_script"
    path: "run_test.sh"
    is_executable: true
  - type: "file"
    path: "../../../resources_test/msdial_demo_files/raw/GCMS"
  info: {}
  dummy_arguments: []
  set_wd_to_resources_dir: false
platform:
  type: "nextflow"
  id: "nextflow"
  variant: "vdsl3"
  directives:
    accelerator: {}
    conda: []
    containerOptions: []
    label: []
    module: []
    pod: []
    publishDir: []
    queue: []
  auto:
    simplifyInput: true
    simplifyOutput: true
    transcript: false
    publish: false
  debug: false
  container: "docker"
platforms: []
info:
  config: "src/msdial/msdial_gcms/config.vsh.yaml"
  platform: "nextflow"
  output: "target/nextflow/msdial/msdial_gcms"
  viash_version: "0.5.12"
  git_commit: "a104f1965e7567cfb5c0504d3412a89f45f2de8b"
  git_remote: "https://github.com/czbiohub/mspipelines"
